<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pearllyn Clavecillas">
<meta name="dcterms.date" content="2024-09-20">

<title>MAXIMUM LIKELIHOOD EXTIMATION OF MIXTURE OF UNIVARIATE NORMAL DISTRIBUTION – Thesis2k24</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Thesis2k24</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">MAXIMUM LIKELIHOOD EXTIMATION OF MIXTURE OF UNIVARIATE NORMAL DISTRIBUTION</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">news</div>
                <div class="quarto-category">code</div>
                <div class="quarto-category">analysis</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pearllyn Clavecillas </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 20, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. When we say Probabilistic model it take into account the impact of random events or actions in predicting the potential occurence of future outcomes, thus it make decisions based on likelihoods and probabilities.</p>
<p>GMMs being a probabilistic models, represents normally distributed subpopulations within an overall population, this gives us the idea that it may have more than two components. In fact, a Gaussian mixture model is parameterized by two types of values, the mixture component weights and the component means and variances/covariances. Estimating these said parameters is important in order to measure and diagnose the underlying true values of the population. However, estimating the parameters of the individual normal distribution components is a canonical in modeling data with GMMs.</p>
<p>Furthermore, In frequentist probability theory, models are typically learnedby using the maximum likelihood estimation (MLE) techniques. MLE is an estimation method that allows us to use a sample to estimate the parameters of the probability distribution that generated the sample. It also seeks to maximize the probability or likelihood of the observed data given the model parameters. Unfortunately, finding the maximum likelihood solution for mixture models by differentiating the log-likelihood and solving for 0 is usually analytically impossible (McGonagle et. al). Thus, an algorithm that attempts to find maximum likelihood estimates for models with latent variables like Gaussian mixture models comes to light, called the Expectation-Maximization (EM) algorithm.</p>
<p>Expectation-Maximization algorithm is an iterative algorithm which is a numerical technique for maximum likelihood estimation and is usually used when closed form expression for updating the model parameters can be calculated. It has a convenient property that the maximum likelihood of the data strictly increases with each subsequent iteration, meaning it is guaranteed to approach a local maximum or saddle point. EM algorithm has two steps, the Expectation (E-step) and the Maximization (M-step). The E-step is consist of calculating the expectation of the component assignments for each data point given the model parameters. While the M-step consist of maximizing the expectations calculated in the E-step with respect to the model parameters. This step consist of updating the values of the parameters.</p>
<p>Before proceeding to the Maximum likelihood estimation of the Gaussian Mixture Model let’s have first a quick overview of the MLE of Normal Distribution.</p>
<section id="mle-of-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="mle-of-normal-distribution">MLE of Normal Distribution</h2>
<p>Suppose we have <span class="math inline">\(n\)</span> observations <span class="math inline">\(X_1, \dots, X_n\)</span> from a Gaussian distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>. To find the maximum likelihood estimate (MLE) for <span class="math inline">\(\mu\)</span>, we find the log-likelihood <span class="math inline">\(\ell(\mu)\)</span>, take the derivative with respect to <span class="math inline">\(\mu\)</span>, set it equal to zero, and solve for <span class="math inline">\(\mu\)</span>:</p>
<p>First, the likelihood function <span class="math inline">\(L(\mu)\)</span> is:</p>
<p><span class="math display">\[
L(\mu) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
\]</span></p>
<p>Next, the log-likelihood <span class="math inline">\(\ell(\mu)\)</span> is:</p>
<p><span class="math display">\[
\ell(\mu) = \sum_{i=1}^n \left[\log\left(\frac{1}{\sqrt{2\pi \sigma^2}}\right) - \frac{(x_i - \mu)^2}{2\sigma^2}\right]
\]</span></p>
<p>Now, differentiate the log-likelihood with respect to <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\frac{d}{d\mu} \ell(\mu) = \sum_{i=1}^n \frac{x_i - \mu}{\sigma^2}
\]</span></p>
<p>Setting this equal to zero and solving for <span class="math inline">\(\mu\)</span>, we get:</p>
<p><span class="math display">\[
\mu_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n x_i
\]</span></p>
<p>Note that applying the log function to the likelihood helped decompose the product and removed the exponential function, which allowed us to easily solve for the MLE.</p>
</section>
<section id="mle-of-gaussian-mixture-model" class="level2">
<h2 class="anchored" data-anchor-id="mle-of-gaussian-mixture-model">MLE of Gaussian Mixture Model</h2>
<p>Now we attempt the same strategy for deriving the Maximum Likelihood Estimation (MLE) of the Gaussian Mixture Model (GMM). Our unknown parameters are:</p>
<p><span class="math display">\[
\theta = \{ \mu_1, \dots, \mu_K, \sigma_1, \dots, \sigma_K, \pi_1, \dots, \pi_K \}
\]</span></p>
<p>From the first section of this note, our likelihood function is:</p>
<p><span class="math display">\[
L(\theta | X_1, \dots, X_n) = \prod_{i=1}^n \sum_{k=1}^K \pi_k \mathcal{N}(x_i; \mu_k, \sigma_k^2)
\]</span></p>
<p>So our log-likelihood is:</p>
<p><span class="math display">\[
\ell(\theta) = \sum_{i=1}^n \log \left( \sum_{k=1}^K \pi_k \mathcal{N}(x_i; \mu_k, \sigma_k^2) \right)
\]</span></p>
<p>Looking at the expression above, we already notice a difference between this scenario and the simple setup in the previous section. The summation over the <span class="math inline">\(K\)</span> components “blocks” our log function from being applied directly to the normal densities.</p>
<p>If we follow the same steps as before and differentiate with respect to <span class="math inline">\(\mu_k\)</span> and set the expression equal to zero, we get:</p>
<p><span class="math display">\[
\sum_{i=1}^n \frac{1}{\sum_{k=1}^K \pi_k \mathcal{N}(x_i; \mu_k, \sigma_k)} \pi_k \mathcal{N}(x_i; \mu_k, \sigma_k) \frac{(x_i - \mu_k)}{\sigma_k^2} = 0 \tag{1}
\]</span></p>
<p>Now, we’re stuck because we can’t analytically solve for <span class="math inline">\(\mu_k\)</span>. However, we can make one important observation which provides intuition for what’s to come: if we knew the latent variables <span class="math inline">\(Z_i\)</span>, we could simply gather all our samples <span class="math inline">\(X_i\)</span> such that <span class="math inline">\(Z_i = k\)</span> and use the estimates from the previous section to estimate <span class="math inline">\(\mu_k\)</span>.</p>
<section id="em-informally" class="level3">
<h3 class="anchored" data-anchor-id="em-informally">EM, Informally</h3>
<p>Intuitively, the latent variables <span class="math inline">\(Z_i\)</span> should help us find the MLEs. We first attempt to compute the posterior distribution of <span class="math inline">\(Z_i\)</span> given the observations:</p>
<p><span class="math display">\[
P(Z_i = k | X_i) = \frac{P(X_i | Z_i = k) P(Z_i = k)}{P(X_i)} = \frac{\pi_k N(\mu_k, \sigma^2_k)}{\sum_{k=1}^{K} \pi_k N(\mu_k, \sigma_k)} = \gamma_{Z_i}(k) \tag{2}
\]</span></p>
<p>Now we can rewrite equation (1), the derivative of the log-likelihood with respect to $ _k $, as follows:</p>
<p><span class="math display">\[
\sum_{i=1}^{n} \gamma_{Z_i}(k) (X_i - \mu_k) \sigma^2_k = 0
\]</span></p>
<p>Even though $_{Z_i}(k) $ depends on $_k $, we can cheat a bit and pretend that it doesn’t. Now we can solve for $_k $ in this equation to get:</p>
<p><span class="math display">\[
\hat{\mu}_k = \frac{\sum_{i=1}^{n} \gamma_{Z_i}(k) X_i}{\sum_{i=1}^{n} \gamma_{Z_i}(k)} = \frac{1}{N_k} \sum_{i=1}^{n} \gamma_{Z_i}(k) X_i \tag{3}
\]</span></p>
<p>Where we set $ N_k = <em>{i=1}^{n} </em>{Z_i}(k) $. We can think of $ N_k $ as the effective number of points assigned to component $ k $. We see that $ <em>k $ is therefore a weighted average of the data with weights $</em>{Z_i}(k) $.</p>
<p>Similarly, if we apply a similar method to finding $^2_k $ and $ _k $, we find that:</p>
<p><span class="math display">\[
\hat{\sigma}^2_k = \frac{1}{N_k} \sum_{i=1}^{n} \gamma_{Z_i}(k) (X_i - \hat{\mu}_k)^2 \tag{4}
\]</span></p>
<p><span class="math display">\[
\hat{\pi}_k = \frac{N_k}{n} \tag{5}
\]</span></p>
<p>Again, remember that $_{Z_i}(k) $ depends on the unknown parameters, so these equations are not closed-form expressions. This looks like a vicious circle. But, as Cosma Shalizi says, “one man’s vicious circle is another man’s successive approximation procedure.”</p>
<p>We are now in the following situation:</p>
<ul>
<li>If we knew the parameters, we could compute the posterior probabilities $ _{Z_i}(k) $.</li>
<li>If we knew the posteriors $ _{Z_i}(k) $, we could easily compute the parameters.</li>
</ul>
<p>The EM algorithm, motivated by the two observations above, proceeds as follows:</p>
<ol type="1">
<li>Initialize the $_k $’s, $ _k $’s, and $_k $’s and evaluate the log-likelihood with these parameters.</li>
<li><strong>E-step</strong>: Evaluate the posterior probabilities $_{Z_i}(k) $ using the current values of the $_k $’s and $_k $’s with equation (2).</li>
<li><strong>M-step</strong>: Estimate new parameters $_k $, $^2_k $, and $_k $ with the current values of <span class="math inline">\(\gamma_{Z_i}(k)\)</span> using equations (3), (4), and (5).</li>
<li>Evaluate the log-likelihood with the new parameter estimates. If the log-likelihood has changed by less than some small $$, stop. Otherwise, go back to step 2.</li>
</ol>
<p>The EM algorithm is sensitive to the initial values of the parameters, so care must be taken in the first step. However, assuming the initial values are “valid,” one property of the EM algorithm is that the log-likelihood increases at every step. This invariant proves to be useful when debugging the algorithm in practice.</p>
</section>
<section id="the-em-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-em-algorithm">The EM Algorithm</h3>
<p>The EM algorithm attempts to find maximum likelihood estimates for models with latent variables. In this section, we describe a more abstract view of EM, which can be extended to other latent variable models.</p>
<p>Let <span class="math inline">\(X\)</span> be the entire set of observed variables and <span class="math inline">\(Z\)</span> the entire set of latent variables. The log-likelihood is therefore:</p>
<p><span class="math display">\[
\log(P(X | \Theta)) = \log\left(\sum_Z P(X, Z | \Theta)\right)
\]</span></p>
<p>where we’ve simply marginalized <span class="math inline">\(Z\)</span> out of the joint distribution.</p>
<p>As we noted above, the existence of the sum inside the logarithm prevents us from applying the log to the densities, which results in a complicated expression for the MLE. Now suppose that we observed both <span class="math inline">\(X\)</span> and $Z $. We call ${X, Z} $ the complete data set, and we say $X $ is incomplete. As we noted previously, if we knew $Z $, the maximization would be easy.</p>
<p>We typically don’t know <span class="math inline">\(Z\)</span>, but the information we do have about $Z $ is contained in the posterior $P(Z | X, ) $. Since we don’t know the complete log-likelihood, we consider its expectation under the posterior distribution of the latent variables. This corresponds to the E-step above. In the M-step, we maximize this expectation to find a new estimate for the parameters.</p>
<p>In the E-step, we use the current value of the parameters <span class="math inline">\(\theta_0\)</span> to find the posterior distribution of the latent variables given by <span class="math inline">\(P(Z | X, \theta_0)\)</span>. This corresponds to the $_{Z_i}(k) $ in the previous section. We then use this to find the expectation of the complete data log-likelihood, with respect to this posterior, evaluated at an arbitrary $$. This expectation is denoted $ Q(, _0) $ and it equals:</p>
<p><span class="math display">\[
Q(\theta, \theta_0) = \mathbb{E}_{Z|X, \theta_0} \left[\log(P(X, Z | \theta))\right] = \sum_Z P(Z | X, \theta_0) \log(P(X, Z | \theta))
\]</span></p>
<p>In the M-step, we determine the new parameter <span class="math inline">\(\hat{\theta}\)</span> by maximizing $ Q $:</p>
<p><span class="math display">\[
\hat{\theta} = \arg\max_{\theta} Q(\theta, \theta_0)
\]</span></p>
</section>
<section id="gaussian-mixture-models" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-mixture-models">Gaussian Mixture Models</h3>
<p>Now we derive the relevant quantities for Gaussian mixture models and compare it to our “informal” derivation above. The complete likelihood takes the form:</p>
<p><span class="math display">\[
P(X, Z | \mu, \sigma, \pi) = \prod_{i=1}^{n} \prod_{k=1}^{K} \pi_k^{I(Z_i = k)} N(x_i | \mu_k, \sigma_k)^{I(Z_i = k)}
\]</span></p>
<p>so the complete log-likelihood takes the form:</p>
<p><span class="math display">\[
\log(P(X, Z | \mu, \sigma, \pi)) = \sum_{i=1}^{n} \sum_{k=1}^{K} I(Z_i = k) \left( \log(\pi_k) + \log(N(x_i | \mu_k, \sigma_k)) \right)
\]</span></p>
<p>Note that for the complete log-likelihood, the logarithm acts directly on the normal density, which leads to a simpler solution for the MLE. As we said, in practice, we do not observe the latent variables, so we consider the expectation of the complete log-likelihood with respect to the posterior of the latent variables.</p>
<p>The expected value of the complete log-likelihood is therefore:</p>
<p><span class="math display">\[
\mathbb{E}_{Z|X}\left[\log(P(X, Z | \mu, \sigma, \pi))\right] = \mathbb{E}_{Z|X}\left[\sum_{i=1}^{n} \sum_{k=1}^{K} I(Z_i = k) \left( \log(\pi_k) + \log(N(x_i | \mu_k, \sigma_k)) \right)\right]
\]</span></p>
<p><span class="math display">\[
= \sum_{i=1}^{n} \sum_{k=1}^{K} \mathbb{E}_{Z|X}[I(Z_i = k)] \left( \log(\pi_k) + \log(N(x_i | \mu_k, \sigma_k)) \right)
\]</span></p>
<p>Since $_{Z|X}[I(Z_i = k)] = P(Z_i = k | X) $, we see that this is simply <span class="math inline">\(\gamma_{Z_i}(k)\)</span> which we computed in the previous section. Hence, we have:</p>
<p><span class="math display">\[
\mathbb{E}_{Z|X}\left[\log(P(X, Z | \mu, \sigma, \pi))\right] = \sum_{i=1}^{n} \sum_{k=1}^{K} \gamma_{Z_i}(k) \left( \log(\pi_k) + \log(N(x_i | \mu_k, \sigma_k)) \right)
\]</span></p>
<p>EM proceeds as follows: first choose initial values for <span class="math inline">\(\mu, \sigma, \pi\)</span> and use these in the E-step to evaluate the <span class="math inline">\(\gamma_{Z_i}(k)\)</span>. Then, with $_{Z_i}(k) $ fixed, maximize the expected complete log-likelihood above with respect to <span class="math inline">\(\mu_k, \sigma_k\)</span> and $_k $. This leads to the closed-form solutions we derived in the previous section.</p>
</section>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>In this example, we will assume our mixture components are fully specified Gaussian distributions (i.e., the means and variances are known), and we are interested in finding the maximum likelihood estimates of the $_k $’s.</p>
<p>Assume we have $ K = 2 $ components, so that:</p>
<ul>
<li>$X_i | Z_i = 0 N(5, 1.5) $</li>
<li>$X_i | Z_i = 1 N(10, 2) $</li>
</ul>
<p>The true mixture proportions will be $P(Z_i = 0) = 0.25 $ and $P(Z_i = 1) = 0.75 $.</p>
<p>First, we simulate data from this mixture model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># mixture components</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>mu.true    <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>sigma.true <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">1.5</span>, <span class="dv">2</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># determine Z_i</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">=</span> <span class="fu">rbinom</span>(<span class="dv">500</span>, <span class="dv">1</span>, <span class="fl">0.75</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from mixture model</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>, <span class="at">mean=</span>mu.true[Z<span class="sc">+</span><span class="dv">1</span>], <span class="at">sd=</span>sigma.true[Z<span class="sc">+</span><span class="dv">1</span>])</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(X,<span class="at">breaks=</span><span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Now we write a function to compute the log-likelihood for the incomplete data, assuming the parameters are known. This will be used to determine convergence:</p>
<p>[ () = <em>{i=1}^{n} ( </em>{k=1}^{K} N(x_i; _k, ^2_k) L[i,k] ) ]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>compute.log.lik <span class="ot">&lt;-</span> <span class="cf">function</span>(L, w) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  L[,<span class="dv">1</span>] <span class="ot">=</span> L[,<span class="dv">1</span>]<span class="sc">*</span>w[<span class="dv">1</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  L[,<span class="dv">2</span>] <span class="ot">=</span> L[,<span class="dv">2</span>]<span class="sc">*</span>w[<span class="dv">2</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">rowSums</span>(L))))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since the mixture components are fully specified, for each sample <span class="math inline">\(X_i\)</span>, we can compute the likelihood <span class="math inline">\(P(X_i|Z_i=0)\)</span> and <span class="math inline">\(P(X_i|Z_i=1)\)</span>. We store these values in the columns of matrix <span class="math inline">\(L\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>L <span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow=</span><span class="fu">length</span>(X), <span class="at">ncol=</span> <span class="dv">2</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>L[, <span class="dv">1</span>] <span class="ot">=</span> <span class="fu">dnorm</span>(X, <span class="at">mean=</span>mu.true[<span class="dv">1</span>], <span class="at">sd =</span> sigma.true[<span class="dv">1</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>L[, <span class="dv">2</span>] <span class="ot">=</span> <span class="fu">dnorm</span>(X, <span class="at">mean=</span>mu.true[<span class="dv">2</span>], <span class="at">sd =</span> sigma.true[<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we implement the E and M step in the EM.iter function below. The mixture.EM function is the driver which checks for convergence by computing the log-likelihoods at each step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mixture.EM <span class="ot">&lt;-</span> <span class="cf">function</span>(w.init, L) {</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  w.curr <span class="ot">&lt;-</span> w.init</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># store log-likehoods for each iteration</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  log_liks <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  ll       <span class="ot">&lt;-</span> <span class="fu">compute.log.lik</span>(L, w.curr)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  log_liks <span class="ot">&lt;-</span> <span class="fu">c</span>(log_liks, ll)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  delta.ll <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span>(delta.ll <span class="sc">&gt;</span> <span class="fl">1e-5</span>) {</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    w.curr   <span class="ot">&lt;-</span> <span class="fu">EM.iter</span>(w.curr, L)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    ll       <span class="ot">&lt;-</span> <span class="fu">compute.log.lik</span>(L, w.curr)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    log_liks <span class="ot">&lt;-</span> <span class="fu">c</span>(log_liks, ll)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    delta.ll <span class="ot">&lt;-</span> log_liks[<span class="fu">length</span>(log_liks)]  <span class="sc">-</span> log_liks[<span class="fu">length</span>(log_liks)<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(w.curr, log_liks))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>EM.iter <span class="ot">&lt;-</span> <span class="cf">function</span>(w.curr, L, ...) {</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E-step: compute E_{Z|X,w0}[I(Z_i = k)]</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  z_ik <span class="ot">&lt;-</span> L</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">ncol</span>(L))) {</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    z_ik[,i] <span class="ot">&lt;-</span> w.curr[i]<span class="sc">*</span>z_ik[,i]</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  z_ik     <span class="ot">&lt;-</span> z_ik <span class="sc">/</span> <span class="fu">rowSums</span>(z_ik)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># M-step</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  w.next   <span class="ot">&lt;-</span> <span class="fu">colSums</span>(z_ik)<span class="sc">/</span><span class="fu">sum</span>(z_ik)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(w.next)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#perform EM</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>ee <span class="ot">&lt;-</span> <span class="fu">mixture.EM</span>(<span class="at">w.init=</span><span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>), L)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Estimate = ("</span>, <span class="fu">round</span>(ee[[<span class="dv">1</span>]][<span class="dv">1</span>],<span class="dv">2</span>), <span class="st">","</span>, <span class="fu">round</span>(ee[[<span class="dv">1</span>]][<span class="dv">2</span>],<span class="dv">2</span>), <span class="st">")"</span>, <span class="at">sep=</span><span class="st">""</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Estimate = (0.26,0.74)"</code></pre>
</div>
</div>
<p>Finally, we inspect the evolution of the log-likelihood and note that it is strictly increases:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ee[[<span class="dv">2</span>]], <span class="at">ylab=</span><span class="st">'incomplete log-likelihood'</span>, <span class="at">xlab=</span><span class="st">'iteration'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>